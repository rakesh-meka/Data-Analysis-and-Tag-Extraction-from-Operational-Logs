# ğŸ“Š Data Analysis and Tag Extraction from Operational Logs

## ğŸ“Œ Project Overview

This project provides an end-to-end data analysis pipeline for **exploratory data analysis (EDA), data cleaning, visualization, and automated tag extraction** from operational log data.  
The goal is to transform raw operational recordsâ€”especially free-text issue descriptionsâ€”into structured, actionable insights.

The analysis helps identify common operational problems such as **failures, component issues, delays, and warnings**, enabling better monitoring, reporting, and decision-making.

The entire workflow is implemented using **Python** in a **Jupyter Notebook** environment.

---

## ğŸ› ï¸ Tech Stack & Tools

- **Programming Language**: Python  
- **Environment**: Jupyter Notebook  
- **Libraries Used**:
  - Pandas â€“ Data manipulation and cleaning  
  - NumPy â€“ Numerical operations  
  - Matplotlib â€“ Data visualization  
  - Seaborn â€“ Statistical visualizations  

---

## ğŸ“‚ Project Structure

Data-Analysis-and-Tag-Extraction-from-Operational-Logs/
â”‚
â”œâ”€â”€ TASK-2.xlsx # Raw operational dataset
â”œâ”€â”€ TASK-2-Cleaned.xlsx # Cleaned and processed dataset
â”œâ”€â”€ Analysis.ipynb # Complete EDA, cleaning, visualization & tagging pipeline
â””â”€â”€ README.md # Project documentation


---

## ğŸ“Š Dataset Description

The dataset contains a mix of **numerical, categorical, and free-text fields** representing operational events.

### Key Analysis Performed:
- Identification of **data types** (numerical vs categorical)
- **Unique value counts** to understand data variability
- **Statistical summaries** for numerical columns
- **Frequency analysis** for categorical columns
- Inspection of **text-based issue descriptions**

---

## ğŸ§¹ Data Cleaning Process

To ensure data quality and consistency, the following steps were applied:

### 1. Handling Missing Values
- Numerical columns filled using **median**
- Categorical columns filled using **mode**

### 2. Text Standardization
- Converted all text to **lowercase**
- Removed leading and trailing whitespaces

### 3. Outlier Treatment
- Outliers detected using the **Interquartile Range (IQR)** method
- Outliers were **retained intentionally** for analytical insights

---

## ğŸ“ˆ Exploratory Data Analysis & Visualizations

The project includes multiple visualization techniques to uncover patterns:

- **Distribution Plots** â€“ Understand spread and skewness of numerical data  
- **Count Plots** â€“ Identify dominant categories and frequent events  
- **Boxplots** â€“ Detect and analyze outliers visually  

These visualizations support better interpretation of operational trends.

---

## ğŸ·ï¸ Automated Tag Extraction

Free-text operational descriptions were processed to extract meaningful tags.

### Tags Generated:
- `failure`
- `error`
- `component issue`
- `delay`
- `warning`
- `general`

### Methodology:
- Keyword-based matching
- Semantic filtering for relevance

These tags help classify operational problems and highlight recurring issue types.

---

## ğŸ“Œ Key Insights

- **Failures and component issues** are the most frequent tags, indicating critical focus areas
- Cleaned data is now suitable for **further modeling or advanced analytics**
- Visualization results reveal **patterns and anomalies** useful for operational improvement

---

## ğŸš€ How to Run the Project

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/Data-Analysis-and-Tag-Extraction-from-Operational-Logs.git
cd Data-Analysis-and-Tag-Extraction-from-Operational-Logs

### 2. Install Dependencies

### 3. Run the Notebook 